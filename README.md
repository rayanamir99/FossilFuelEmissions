# FossilFuelEmissions
Analyzes the relationship between Carbon Monoxide and Nitrogen Oxide emissions per country, as reported in 2019.

Our final project centers around the relationship between Carbon Monoxide and Nitrogen Oxide emissions per country, as reported in 2019. The code we compiled reads in data from a CSV file, and performs some basic analysis on it using the NumPy library in Python. We obtained the CSV file with data on Nitrogen Oxide and Carbon Monoxide emissions per country in 2019 on Kaggle, a website known for possessing millions of datasets available for analysis. Our code implements a least squares regression line because we hoped to minimize the variance, otherwise known as the sum of the square of errors. This linear algebra specific topic is the focus of our project, and can help us understand relationships between real world emissions.

To put the code into words, we first started with downloading a CSV file off of aforementioned Kaggle. The Python code first reads the contents of the CSV file into a string, and then uses the split() method to split the string into individual lines. It then iterates over these lines and uses the split() method again to split each line into its constituent values, which are separated by commas. This produces a 2D matrix of the data, where each row of the matrix represents a row from the original file and each column represents a value in that row.

The data consisted of 3 columns once we cleaned it. One for the country name, the second for the Nitrogen Oxide output, and the third for Carbon Monoxide output. For example, the country of the Czech Republic had roughly 15,700 metric tons of Nitrogen Oxide output, while their Carbon Monoxide output was around 76,500 metric tons. Once the data had been read and parsed into a matrix, the code extracted two columns of data: the nitrogen oxide levels (x) and the carbon monoxide levels (y). It then converts these columns into NumPy arrays, which are specialized data structures for working with numerical data in Python. NumPy arrays are more efficient than regular Python lists because they are stored in contiguous blocks of memory, which makes them faster to access and manipulate.

The need to minimize variance is especially prevalent on our project because of the numerous outliers which would skew our data if other analysis methods were implemented. The two vectors that were used to construct the matrix was a vector full of ones and the Nitrogen Oxide emissions while the b vector was the Carbon Monoxide emissions. 

The code then performs some matrix operations on the x and y arrays to compute the values of x_hat. Specifically, it creates a new matrix A where each row is of the form [x, 1], where x is a value from the x array and 1 is a constant. This matrix is then transposed and multiplied by itself to produce new_A, and it is also multiplied by the y array to produce new_B. Finally, the solve() function from the numpy.linalg module is used to solve the system of equations new_A * x_hat = new_B for x_hat.

In the graph below, we can see that the coefficient of determination is the square root of .767, or .87. This indicates that the line used strongly represents the data presented. In terms of the real world, this means that if a country has a higher level of Nitrogen Oxide emissions, they would also likely have a higher level of Carbon Monoxide emissions due to the fact that the two are positively correlated. 

With the data we collected, there was a strong positive association between the usage of Carbon Monoxide and Nitrogen Oxide. The value of 4.76 as the slope shows us that for every 1 ton of Nitrogen Oxide produced, there is 4.76 tons of Carbon Monoxide produced on average by that same country. 

We found the total error to be 1.16 * 1015 which is an understandably large number considering the size of the numbers that we were using in our calculations. The first five values of our projection matrix were calculated to be [2,417,315.430405863, 240,687.11066426738, 2,448.211.472708612, 130,612.04983156244, 762,895.5723506464]. This projection matrix represents the orthogonal projection of the matrix with the vector full of ones and the Nitrogen Oxide emissions onto a straight line parallel to b which represents the Carbon Monoxide emissions. Additionally, the y-intercept of 129,442.67154949589 and the slope of 4.759761812384194 represent the first and second terms of the least squares solution, x-hat,  respectively. These values therefore yield the equation b=129,442.67154949589 +  4.759761812384194t. 
When calculating the total error in the graph, we then had to check if our error and projection vectors were accurate. Using the formula of p*e = 0 (because e = b-p), we checked to see if the scalar produced would be zero. When this was calculated, it came out to be 1.818, which is definitely due to rounding errors. Given the size of the total error is in the quadrillions, this number does a pretty good job at showing how the projection vector and the error vector are orthogonal to each other.

Within the error vector itself, it has some large values attached, however we cannot look past the massive numbers within the dataset. In the error vector, there are many values above the projection and below the projection, and that is normal in the world of statistics. From the error, we learn that while the projection is not fully accurate, it is our best guess at a worldwide pollution problem. With tracking the levels of Nitrogen Oxide in each country, we can now easily infer how much Carbon Monoxide pollution is happening too. Even though there are large numbers attached, the error captures the predictions quite well, with very strong R and R2 values. The R2 value shows us that the model is able to explain approximately 75% of the variation within the Carbon Monoxide output and the Nitrogen oxide output (in metric tons). 
With this, we can successfully say that there was an association between the two, and can extrapolate our data when talking about worldwide pollution, and the errors attached within this focus on finding a reliable renewable energy source.

This code is applicable in a variety of situations where you need to read data from a CSV file and perform some basic analysis on it. For example, you could use it to read data from a survey or experiment and compute the average, median, or other statistical measures of the data. You could also use it to fit a line or curve to the data and use that to make predictions or draw conclusions about the underlying process that generated the data.

In the specific case of this code, it appears that the x and y arrays represent the nitrogen oxide and carbon monoxide levels in some environment, and the code is computing the values of x_hat as a way of fitting a line or curve to the data. This could potentially be used to model the relationship between these two pollutants and make predictions about how one will vary as a function of the other. However, without more information about the context and meaning of the data, it is difficult to say exactly what the code is intended to accomplish.

The data analysis that our group conducted could have more real world applicability if we took into account the leading industries of the countries analyzed as well. By taking into account countries' most prominent industries, we would be able to see if there was a correlation between the most prominent industries in each country and Carbon Monoxide and Nitrogen Oxide pollution. The reason that this correlation is important is because countries have different industries that they focus on depending on various factors which therefore leads to different pollutants being released. For example, the electricity and heat production industry produces the most Carbon Monoxide pollution and China leads the way in terms of energy consumption. On the other hand, 
Nitrogen Oxide emissions are the product of the agriculture industry which is most prevalent in the United States. By taking into account the industries that are most prevalent in each country, we would be able to pinpoint what emissions are not vital to the country's economy and could be reduced. For example, the agricultural industry in the United States is too vital on the global scale to tackle in comparison to our energy consumption which still pales in comparison to countries like China or Russia. 

We learned a lot from this project, and took away things that were not necessarily linear algebra based. The first thing is that data is difficult to clean, especially when doing it with code. We had to parse through many datasets, but a lot of them had different ways of using the ‘null’ function, and having to deal with missing values. One other thing we learned was that some datasets are massive, and simply have no association between two variables. We came across sets that had nothing in common, and it became way more difficult than we thought to make a linear model between two things. Things like computer science and data science are things that need to be worked on a lot, but with practice, can be a massive tool to billions of people in the future, dealing with things like optimization, efficiency, and turning input into better output. 
